{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_parent_directory_path():\n",
    "    return os.path.dirname(\n",
    "        os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "    )\n",
    "\n",
    "def add_directory_to_sys_path(directory_path):\n",
    "    return sys.path.insert(-1, directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "#import telegram_send\n",
    "import os, sys, inspect\n",
    "add_directory_to_sys_path(get_parent_directory_path())\n",
    "\n",
    "from dataloader import DataLoader\n",
    "import lstm as lstm_utils\n",
    "import validate as validator\n",
    "from constant import Constant\n",
    "from parameters import Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## utilities.py\n",
    "\n",
    "def get_numbers_of_batch(dataloader):\n",
    "    return dataloader.num_batch()\n",
    "\n",
    "\n",
    "def load_dataloader(METADATA_PATH, BATCH_SIZE, LABEL_COLUMN_NAME, EXTRACTED_FEATURE_NAME=None, is_training=False):\n",
    "    return DataLoader(file_path=METADATA_PATH\n",
    "                                  , batch_size=BATCH_SIZE\n",
    "                                  , label_column_name=LABEL_COLUMN_NAME\n",
    "                                  , is_training=is_training\n",
    "                                  , use_extracted_feature=EXTRACTED_FEATURE_NAME\n",
    "                                  )\n",
    "\n",
    "def get_batch(train_dataloader):\n",
    "    return train_dataloader.next_batch()\n",
    "\n",
    "\n",
    "def chunk_batch_X(batch_X, chunk_size, timestep):\n",
    "    return list(\n",
    "        map(\n",
    "            lambda X: X[:, timestep*chunk_size:(timestep+1)*chunk_size]\n",
    "            , batch_X\n",
    "        )\n",
    "    )\n",
    "\n",
    "def split_X(batch_X, split_indices):\n",
    "    \"\"\"\n",
    "    params @batch_X [a list of ndarray] (length : batch_size)\n",
    "    params @split_indices [a list of integer]\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def debug():\n",
    "        def test(X):\n",
    "            return list(map(lambda X: X.shape,  np.hsplit(X, split_indices)))\n",
    "        print(list(map(lambda X: test(X), batch_X)))\n",
    "    # debug()\n",
    "    \n",
    "    return list(map(lambda X: np.hsplit(X, split_indices), batch_X))\n",
    "\n",
    "def get_split_indices(IMAGE_WIDTH, WINDOW_NUM):\n",
    "    return list(map(lambda i: i*int(IMAGE_WIDTH/WINDOW_NUM), range(1, WINDOW_NUM+1)))\n",
    "\n",
    "def get_current_chunk(batch_X_chunks, selected_window_index):\n",
    "    return list(\n",
    "        map(\n",
    "            lambda X_chunks: X_chunks[selected_window_index]\n",
    "            , batch_X_chunks\n",
    "        )\n",
    "   )\n",
    "\n",
    "def get_context_chunk(batch_X_chunks, selected_window_index, context_window_size=1):\n",
    "    \"\"\"\n",
    "    params @batch_X_chunks[a list of a list of ndarrays]\n",
    "    params @selected_window\n",
    "    \"\"\"\n",
    "    def _index_clamp_to_positive(index): \n",
    "        return 0 if index < 0 else index\n",
    "    \n",
    "    def _get_before_chunk_indices():\n",
    "        return _index_clamp_to_positive(selected_window_index-context_window_size), selected_window_index\n",
    "    \n",
    "    def _get_after_chunk_indices():\n",
    "        return selected_window_index+1, selected_window_index+1+context_window_size\n",
    "        \n",
    "    return list(\n",
    "        map(\n",
    "            lambda X_chunks: X_chunks[_get_before_chunk_indices()[0]:_get_before_chunk_indices()[1]]\\\n",
    "                              + X_chunks[_get_after_chunk_indices()[0]:_get_after_chunk_indices()[1]]\n",
    "            , batch_X_chunks\n",
    "        )\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### models.py\n",
    "\n",
    "def set_X(IMAGE_HEIGHT, window_size):\n",
    "    return tf.placeholder(tf.float32, [None, IMAGE_HEIGHT, window_size])\n",
    "\n",
    "def set_window_size(IMAGE_WIDTH, WINDOW_NUM):\n",
    "    return int(IMAGE_WIDTH/WINDOW_NUM)\n",
    "\n",
    "def set_y(N_CLASS):\n",
    "    return tf.placeholder(tf.float32, [None, N_CLASS])\n",
    "\n",
    "def unstack_X_by_timestep(X, window_size):\n",
    "    return tf.unstack(X, num=window_size, axis=2)\n",
    "\n",
    "def set_rnn_cell(RNN_TYPE, EMBEDDING_DIMENSION):\n",
    "    return RNN_TYPE(EMBEDDING_DIMENSION, state_is_tuple=False )\n",
    "\n",
    "def wrap_attention(rnn_cell, attention_length):\n",
    "    return tf.contrib.rnn.AttentionCellWrapper(\n",
    "        rnn_cell, attention_length\n",
    "        , state_is_tuple=False\n",
    "    )\n",
    "\n",
    "def stack_rnn_cells(make_rnn_cell, num_layers):\n",
    "    return list(map(\n",
    "        lambda i: make_rnn_cell\n",
    "        , range(num_layers)\n",
    "    ))\n",
    "\n",
    "def layer_rnn_cells(stacked_rnn_cells):\n",
    "    return tf.nn.rnn_cell.MultiRNNCell(\n",
    "        stacked_rnn_cells\n",
    "        , state_is_tuple=False\n",
    "    )\n",
    "\n",
    "def run_rnn(rnn_cells, X):\n",
    "    return tf.contrib.rnn.static_rnn(\n",
    "        rnn_cells, X, dtype=tf.float32\n",
    "    )\n",
    "\n",
    "def set_fully_connected_layer(X, num_hidden_units, activation):\n",
    "    return tf.layers.dense(X, num_hidden_units, activation=activation)\n",
    "\n",
    "def get_logits(X, N_CLASS):\n",
    "    return tf.layers.dense(X, N_CLASS)\n",
    "\n",
    "def calculate_losses(LOSS_FUNCTION, labels, logits):\n",
    "    return LOSS_FUNCTION(labels, logits)\n",
    "\n",
    "def calculate_mean_loss(losses):\n",
    "    return tf.reduce_mean(losses)\n",
    "\n",
    "def set_train_step(Optimizer, target_loss):\n",
    "    return Optimizer.minimize(target_loss)\n",
    "\n",
    "def build_attention_model(project_constant, data_constant, experiment_parameters):\n",
    "    X = set_X(\n",
    "        data_constant.IMAGE_HEIGHT\n",
    "          , set_window_size(\n",
    "              data_constant.IMAGE_WIDTH\n",
    "              , experiment_parameters.WINDOW_NUM\n",
    "          )\n",
    "    )\n",
    "    \n",
    "    y = set_y(experiment_parameters.N_CLASS)\n",
    "        \n",
    "    # unstack X\n",
    "    unstacked_X = unstack_X_by_timestep(\n",
    "        X\n",
    "        , set_window_size(\n",
    "          data_constant.IMAGE_WIDTH\n",
    "          , experiment_parameters.WINDOW_NUM\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # stack rnn cells\n",
    "    stacked_rnn_cells = []\n",
    "    for i in range(experiment_parameters.NUM_RNN_LAYERS):\n",
    "        stacked_rnn_cells.append(\n",
    "          wrap_attention(\n",
    "                set_rnn_cell(\n",
    "                    experiment_parameters.RNN_TYPE\n",
    "                    , experiment_parameters.EMBEDDING_DIMENSION\n",
    "                )\n",
    "                , experiment_parameters.ATTENTION_LENGTH\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # run rnn\n",
    "    _, encoding = run_rnn(\n",
    "        layer_rnn_cells(stacked_rnn_cells)\n",
    "        , unstacked_X\n",
    "    )\n",
    "   \n",
    "    # classification\n",
    "    logits = get_logits(\n",
    "        set_fully_connected_layer(\n",
    "            encoding\n",
    "            , experiment_parameters.NUM_FC_HIDDEN_UNITS\n",
    "            , experiment_parameters.Activation\n",
    "        )\n",
    "        , experiment_parameters.N_CLASS\n",
    "    )\n",
    "    \n",
    "    # loss\n",
    "    mean_loss = calculate_mean_loss(\n",
    "        calculate_losses(experiment_parameters.LOSS_FUNCTION\n",
    "                         , labels=y, logits=logits)\n",
    "    )\n",
    "    train_step = set_train_step(experiment_parameters.Optimizer, mean_loss)\n",
    "    \n",
    "    # accuracy\n",
    "    predictions = tf.equal(tf.argmax(y, 1), tf.argmax(logits, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(predictions, \"float\"))\n",
    "    \n",
    "    return X, y, logits, mean_loss, train_step, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5863\n",
      "[[ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ndef small_test(experiment_parameters):\\n    return list(\\n        map(\\n        lambda i: wrap_attention(\\n            set_rnn_cell(\\n                experiment_parameters.RNN_TYPE\\n                , experiment_parameters.NUM_HIDDENS\\n            )\\n            , experiment_parameters.ATTENTION_LENGTH\\n        )\\n        , [1, 2]\\n    )\\n               )\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# playground.py\n",
    "def test(project_constant, data_constant, experiment_parameters):\n",
    "    train_dataloader = load_dataloader(project_constant.METADATA_PATH\n",
    "                    , experiment_parameters.BATCH_SIZE\n",
    "                    , project_constant.LABEL_COLUMN_NAME\n",
    "                    , data_constant.FEATURE_NAME\n",
    "                    , is_training=True\n",
    "                   )\n",
    "    _, batch_y = get_batch(train_dataloader)\n",
    "    print(batch_y)\n",
    "    \n",
    "    return None\n",
    "\n",
    "#test(Constant.Project2, Constant.Data.ChromaStftHop512, Parameters.Attention.Experiment1)\n",
    "\n",
    "\"\"\"\n",
    "def small_test(experiment_parameters):\n",
    "    return list(\n",
    "        map(\n",
    "        lambda i: wrap_attention(\n",
    "            set_rnn_cell(\n",
    "                experiment_parameters.RNN_TYPE\n",
    "                , experiment_parameters.NUM_HIDDENS\n",
    "            )\n",
    "            , experiment_parameters.ATTENTION_LENGTH\n",
    "        )\n",
    "        , [1, 2]\n",
    "    )\n",
    "               )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5863\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x20455d208>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "WARNING:tensorflow:<tensorflow.contrib.rnn.python.ops.rnn_cell.AttentionCellWrapper object at 0x204558b70>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x204558c18>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "WARNING:tensorflow:<tensorflow.contrib.rnn.python.ops.rnn_cell.AttentionCellWrapper object at 0x2176a8e48>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "1.10579 0.366667\n"
     ]
    }
   ],
   "source": [
    "### MAIN.py\n",
    "def main(project_constant, data_constant, experiment_parameters):\n",
    "    train_dataloader = load_dataloader(project_constant.METADATA_PATH\n",
    "                    , experiment_parameters.BATCH_SIZE\n",
    "                    , project_constant.LABEL_COLUMN_NAME\n",
    "                    , data_constant.FEATURE_NAME\n",
    "                    , is_training=True\n",
    "                   )\n",
    "    \n",
    "    with tf.Graph().as_default():\n",
    "        X, y, logits, mean_loss, train_step, accuracy = build_attention_model(\n",
    "            project_constant\n",
    "            , data_constant\n",
    "            , experiment_parameters\n",
    "        )\n",
    "        #for i in range(get_numbers_of_batch(train_dataloader)):\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            for i in range(1):\n",
    "                batch_X, batch_y = get_batch(train_dataloader)\n",
    "\n",
    "                batch_X_chunks = split_X(batch_X\n",
    "                                         , get_split_indices(\n",
    "                                             data_constant.IMAGE_WIDTH\n",
    "                                             , experiment_parameters.WINDOW_NUM\n",
    "                                         )\n",
    "                                        )\n",
    "                #for j in range(BasicLSTM.Experiment1.WINDOW_NUM):\n",
    "                for selected_window_index in range(1):\n",
    "                    current_chunk = get_current_chunk(batch_X_chunks, selected_window_index)\n",
    "                    feed_dict = {X: current_chunk, y: batch_y}\n",
    "                    mean_loss_, accuracy_ = sess.run([mean_loss, accuracy], feed_dict)\n",
    "                    print(mean_loss_, accuracy_)\n",
    "                    #context_chunk = get_context_chunk(batch_X_chunks, selected_window_index\n",
    "                    #                                  , context_window_size=1)\n",
    "\n",
    "    return None\n",
    "\n",
    "main(Constant.Project2, Constant.Data.ChromaStftHop512, Parameters.Attention.Experiment1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
